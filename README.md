モデル$M$は入力次元が$k$であり，出力次元が$1$の全結合ニューラルネットワークとします。具体的には，入力系列$A = \left( a_1, a_2, \cdots, a_k \right)$に対して，ある実数$B = M \left( A \right)$を出力するニューラルネットワークであり，このモデル$A$を学習することを考えます。データの集合は$D = \Set{ \left( A_i, B_i \right) }_{i = 1}^N$は与えられているものとし，損失関数は RMSE で与えられるものとします。このモデルの学習は PyTorch を使えば簡単に実装できます。この設定に加えて，モデル$M$の入力に位置エンコーディングを行うことを考えます。

位置エンコーディングは次のように構成します。パラメータ$w$を持つ微分方程式

$$
\dfrac{ dp (t) }{ dt } = h ( t, p (t), w )
$$

を考えます。この微分方程式から得られる系列$p(t_1), p(t_2), \cdots, p(t_k)$をそれぞれ位置が$1, 2, \cdots, k$に対応する位置エンコーディングであり，具体的には，入力系列$A = \left( a_1, a_2, \cdots, a_k \right)$に対して，位置エンコーディング後の系列は$A^\prime = \left( p(t_1)a_1, p(t_2)a_2, \cdots, p(t_k)a_k \right)$となるものとします。$A^\prime$をモデル$M$に入力して，対応するラベル$B$とのRMSEを計算していくことでモデル$M$およびダイナミクス$h ( t, p (t), w )$を学習させたいです。

上記設定をPyTorchとtorchdiffeqによって実装することは可能ですか？

